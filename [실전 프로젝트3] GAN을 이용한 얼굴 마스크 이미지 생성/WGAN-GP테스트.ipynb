{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjzxAWbqQym"
      },
      "source": [
        "#### <b>Problem 1. 나만의 모델을 만들어 학습 및 평가하기</b>\n",
        "\n",
        "* 나만의 GAN 모델을 이용해 <b>최대한 높은 FID 점수</b>를 받아보세요.\n",
        "    * (Hint) 200 epochs 이상으로 학습해보기\n",
        "    * (Hint) DCGAN의 아키텍처를 효율적으로 바꿔보기\n",
        "    * (Hint) WGAN 등 [다른 아키텍처들을](https://github.com/eriklindernoren/PyTorch-GAN) 적용해보기\n",
        "    * (Hint) 사전 학습된(pre-trained) GAN 모델 사용해보기\n",
        "* 결과적으로 자신이 학습한 모델의 <b>최종 FID 점수(score)를 작성</b>하세요.\n",
        "    * 마스크 착용 및 미착용 이미지를 <b>각각 1,000장씩 생성</b>하여 FID를 계산합니다.\n",
        "    * 마스크 착용: {답을 쓰세요.}\n",
        "    * 마스크 미착용: {답을 쓰세요.}\n",
        "* 결과 이미지의 해상도는 1 X 64 X 64가 되어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipBUQJT7nD2k",
        "outputId": "aad8eb07-fe37-4f48-d686-a9745dc766b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Face-Mask-Classification-20000-Dataset'...\n",
            "remote: Enumerating objects: 20017, done.\u001b[K\n",
            "remote: Total 20017 (delta 0), reused 0 (delta 0), pack-reused 20017\u001b[K\n",
            "Receiving objects: 100% (20017/20017), 600.78 MiB | 12.66 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Checking out files: 100% (20001/20001), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ndb796/Face-Mask-Classification-20000-Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhns1AxDedRU",
        "outputId": "fec950f0-12a6-4dd9-cc90-7f0f8959d76b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 18000\n",
            "Class names: ['with_mask', 'without_mask']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.Grayscale(1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5), (0.5)) # normalization\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data_dir = './Face-Mask-Classification-20000-Dataset/'\n",
        "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms_train)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "print('Train dataset size:', len(train_dataset))\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "print('Class names:', class_names)\n",
        "\n",
        "!mkdir -p ./results/custom/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uxBLXcqP7Tuj"
      },
      "outputs": [],
      "source": [
        "latent_dim = 100\n",
        "n_classes = 2\n",
        "\n",
        "\n",
        "# 생성자(Generator) 클래스 정의\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # 레이블 정보를 임베딩 차원으로 매핑하여 사용\n",
        "        self.label_embed = nn.Embedding(n_classes, n_classes)\n",
        "\n",
        "        self.init_size = 4\n",
        "        self.layer1 = nn.Sequential(nn.Linear(latent_dim + n_classes, 512 * self.init_size * self.init_size)) \n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(512, 512, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(512, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1), \n",
        "            nn.BatchNorm2d(256, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1), \n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1), \n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 1, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        # 노이즈(noise) 벡터와 레이블 임베딩을 순차적으로 연결하여 입력\n",
        "        inputs = torch.cat((noise, self.label_embed(labels)), -1)\n",
        "        output = self.layer1(inputs)\n",
        "        output = output.view(output.size(0), 512, self.init_size, self.init_size)\n",
        "        output = self.conv_blocks(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "# 판별자(Discriminator) 클래스 정의\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def make_block(in_channels, out_channels, bn=True):\n",
        "            # 하나의 블록(block)을 반복할 때마다 너비와 높이는 2배씩 감소\n",
        "            block = [nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)]\n",
        "            block.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            block.append(nn.Dropout2d(0.25))\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_channels, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            *make_block(2, 32, bn=False),\n",
        "            *make_block(32, 64),\n",
        "            *make_block(64, 128),\n",
        "            *make_block(128, 256),\n",
        "            *make_block(256, 512),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512*2*2, 1),\n",
        "        )\n",
        "\n",
        "        # 레이블 정보를 임베딩 차원으로 매핑하여 사용\n",
        "        self.label_embed = nn.Embedding(n_classes, 1 * 64* 64)\n",
        "\n",
        "    # 이미지에 대한 판별 결과를 반환\n",
        "    def forward(self, img, labels):\n",
        "        # 이미지 벡터와 레이블 임베딩을 순차적으로 연결하여 입력\n",
        "        embed = self.label_embed(labels).view((img.size(0), 1, 64,64))\n",
        "        inputs = torch.cat((img, embed), 1)\n",
        "        output = self.conv_blocks(inputs)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.classifier(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3JUVu7cULpRG"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.autograd as autograd\n",
        "Tensor = torch.cuda.FloatTensor\n",
        "def compute_gradient_penalty(D, real_samples, fake_samples, labels):\n",
        "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    # Random weight term for interpolation between real and fake samples\n",
        "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
        "    # Get random interpolation between real and fake samples\n",
        "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
        "    d_interpolates = D(interpolates,labels)\n",
        "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "    # Get gradient w.r.t. interpolates\n",
        "    gradients = autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hA2WyUTApJMW"
      },
      "outputs": [],
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XjRwEW6Na6LX"
      },
      "outputs": [],
      "source": [
        "def critic_loss(r_logit, f_logit):\n",
        "    real_loss = - torch.mean(r_logit)\n",
        "    fake_loss = torch.mean(f_logit)\n",
        "    return real_loss, fake_loss\n",
        "\n",
        "def generator_loss(f_logit):\n",
        "    fake_loss = - torch.mean(f_logit)\n",
        "    return fake_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8wAJJnGfoP-g"
      },
      "outputs": [],
      "source": [
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "generator.cuda()\n",
        "discriminator.cuda()\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)\n",
        "\n",
        "# 학습률(learning rate) 설정\n",
        "lr = 0.0002\n",
        "\n",
        "# 생성자와 판별자를 위한 최적화 함수\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IlN5EnZ4I_O"
      },
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "generator.cuda()\n",
        "generator.load_state_dict(torch.load(\"CustomGenerator.pt\"))\n",
        "discriminator.load_state_dict(torch.load(\"CustomDiscriminator.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obdn9mTMoyli",
        "outputId": "f0bfccfd-1840-4404-9ddc-c31bc3da83f3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "\n",
        "n_epochs = 500 # 학습의 횟수(epoch) 설정\n",
        "sample_interval = 1000 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
        "critic_n = 5\n",
        "lambda_gp = 10\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, (imgs, labels) in enumerate(train_dataloader):\n",
        "\n",
        "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
        "        real = torch.cuda.FloatTensor(imgs.shape[0], 1).fill_(1.0) # 진짜(real): 1\n",
        "        fake = torch.cuda.FloatTensor(imgs.shape[0], 1).fill_(0.0) # 가짜(fake): 0\n",
        "\n",
        "        real_imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # 랜덤 노이즈(noise) 및 랜덤 레이블(label) 샘플링\n",
        "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n",
        "        generated_labels = torch.randint(0, n_classes, (imgs.shape[0],)).cuda()\n",
        "\n",
        "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
        "        optimizer_D.zero_grad()\n",
        "        generated_imgs = generator(z,generated_labels)\n",
        "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
        "        real_logit = discriminator(real_imgs, labels)\n",
        "        fake_logit = discriminator(generated_imgs.detach(), generated_labels)\n",
        "\n",
        "        real_loss, fake_loss = critic_loss(real_logit, fake_logit)\n",
        "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, generated_imgs.data, generated_labels)\n",
        "        d_loss = (real_loss + fake_loss) +lambda_gp * gradient_penalty\n",
        "        \n",
        "\n",
        "        # 판별자(discriminator) 업데이트\n",
        "        d_loss.backward()\n",
        "\n",
        "        optimizer_D.step()\n",
        "\n",
        "        if i % critic_n == 0:\n",
        "\n",
        "            \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # 이미지 생성\n",
        "            generated_imgs = generator(z, generated_labels)\n",
        "            # 생성자(generator)의 손실(loss) 값 계산\n",
        "            g_loss = generator_loss(discriminator(generated_imgs, generated_labels))\n",
        "            # 생성자(generator) 업데이트\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "        \n",
        "        \n",
        "\n",
        "        done = epoch * len(train_dataloader) + i\n",
        "        if done % sample_interval == 0:\n",
        "            # 클래스당 8개의 이미지를 생성하여 2 X 8 격자 이미지에 출력\n",
        "            z = torch.normal(mean=0, std=1, size=(n_classes * 8, latent_dim)).cuda()\n",
        "            labels = torch.LongTensor([i for i in range(n_classes) for _ in range(8)]).cuda()\n",
        "            generated_imgs = generator(z, labels)\n",
        "            save_image(generated_imgs, f\"./results/custom/{done}.png\", nrow=8, normalize=True)\n",
        "\n",
        "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
        "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "p37BxUwb2NIb"
      },
      "outputs": [],
      "source": [
        "torch.save(generator.state_dict(), \"CustomGenerator.pt\")\n",
        "torch.save(discriminator.state_dict(), \"CustomDiscriminator.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a4L4Xq93Cf-l"
      },
      "outputs": [],
      "source": [
        "!mkdir ./results/custom/with_mask/\n",
        "!mkdir ./results/custom/without_mask/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3pDEiWZ0eNW",
        "outputId": "b0c4b2c3-e037-476d-f8e4-54d9aca412ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generator = Generator()\n",
        "generator.cuda()\n",
        "generator.load_state_dict(torch.load(\"CustomGenerator.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ziClY5I9CexF"
      },
      "outputs": [],
      "source": [
        "# 마스크를 착용한 총 10 * 100개의 얼굴 이미지를 생성\n",
        "for i in range(10):\n",
        "    # 랜덤 노이즈(noise) 및 랜덤 레이블(label) 샘플링\n",
        "    z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
        "    generated_labels = torch.cuda.IntTensor(100).fill_(0)\n",
        "    # 이미지 생성\n",
        "    generated_imgs = generator(z, generated_labels)\n",
        "\n",
        "    for j in range(100):\n",
        "        save_image(generated_imgs.data[j], f'./results/custom/with_mask/{i * 100 + j}.png', normalize=True)\n",
        "\n",
        "\n",
        "# 마스크를 착용하지 않은 총 10 * 100개의 얼굴 이미지를 생성\n",
        "for i in range(10):\n",
        "    # 랜덤 노이즈(noise) 및 랜덤 레이블(label) 샘플링\n",
        "    z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
        "    generated_labels = torch.cuda.IntTensor(100).fill_(1)\n",
        "    # 이미지 생성\n",
        "    generated_imgs = generator(z, generated_labels)\n",
        "\n",
        "    for j in range(100):\n",
        "        save_image(generated_imgs.data[j], f'./results/custom/without_mask/{i * 100 + j}.png', normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GRgzYfBMtkd",
        "outputId": "b5627bbe-87d1-422e-af30-a96e5d4646cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-frechet-inception-distance'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Total 22 (delta 0), reused 0 (delta 0), pack-reused 22\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hukkelas/pytorch-frechet-inception-distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF9_4Qs27IT3",
        "outputId": "a2d4ef07-8af4-466e-de40-665e3f27e765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking for images in ./results/custom/without_mask/*.png\n",
            "Looking for images in ./results/custom/without_mask/*.jpg\n",
            "Looking for images in ./Face-Mask-Classification-20000-Dataset/test/without_mask/*.png\n",
            "Looking for images in ./Face-Mask-Classification-20000-Dataset/test/without_mask/*.jpg\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100% 104M/104M [00:00<00:00, 188MB/s] \n",
            "262.05855877899194\n"
          ]
        }
      ],
      "source": [
        "# 평가 수행\n",
        "!python ./pytorch-frechet-inception-distance/fid.py --path1 ./results/custom/without_mask --path2 ./Face-Mask-Classification-20000-Dataset/test/without_mask --batch-size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJMhWNis7JpQ",
        "outputId": "afd18932-b35b-409d-e3a3-2a44ede17191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking for images in ./results/custom/with_mask/*.png\n",
            "Looking for images in ./results/custom/with_mask/*.jpg\n",
            "Looking for images in ./Face-Mask-Classification-20000-Dataset/test/with_mask/*.png\n",
            "Looking for images in ./Face-Mask-Classification-20000-Dataset/test/with_mask/*.jpg\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "349.387956651986\n"
          ]
        }
      ],
      "source": [
        "# 평가 수행\n",
        "!python ./pytorch-frechet-inception-distance/fid.py --path1 ./results/custom/with_mask --path2 ./Face-Mask-Classification-20000-Dataset/test/with_mask --batch-size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqwVe5mv87MB",
        "outputId": "94e5e565-8e8f-4cbb-97a8-373def2bf33d"
      },
      "outputs": [],
      "source": [
        "# ./results/custom/ 폴더의 모든 파일을 results.zip라는 이름으로 압축\n",
        "!zip ./results.zip -r ./results/custom/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Zz8k4L9a9cKk",
        "outputId": "c8d92dd1-d777-4dfd-c5b2-d2cd9e55a2ac"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a7cd5ba0-f580-431b-bdb4-6f023ada18c4\", \"results.zip\", 16517678)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Google Colab으로부터 results.zip 압축 파일 다운로드\n",
        "from google.colab import files\n",
        "\n",
        "files.download('./results.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4ye2sOx7ID_8",
        "outputId": "7e3e8a0e-796b-4b6b-a87b-1dfb119d987d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1104c389-6fb7-435b-bf93-7d4d11b33f88\", \"CustomDiscriminator.pt\", 6339906)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a43d4783-d39e-43db-b407-699245ec0211\", \"CustomGenerator.pt\", 19047155)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download('./CustomDiscriminator.pt')\n",
        "files.download('./CustomGenerator.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXMAdfOt66Oh"
      },
      "source": [
        "* PPT에 들어갈 내용\n",
        "    1. 최종적으로 얻은 점수 (마스크 미착용 FID 점수 + 마스크 착용 FID 점수)\n",
        "    2. 좋은 결과를 만들기 위해 어떤 전략을 사용했는지, 그 이유는 무엇인지\n",
        "    3. 소스코드에서 핵심이 되는 부분 캡처 사진 및 설명\n",
        "    4. 자신의 GAN에서 생성된 이미지들 캡처 사진\n",
        "* 점수 판정 기준\n",
        "    * <b>FID의 점수 합이 가장 작은 팀</b>이 1등입니다.\n",
        "    * 마스크 미착용 FID 점수 = 171.67이고, 마스크 착용 FID 점수 = 114.97이라면?\n",
        "    * 최종 점수 = 171.67 + 114.97 = 286.64\n",
        "* 최종적으로 <b>팀 단위로 제출할 파일</b>은 다음과 같습니다.\n",
        "    1. PPT 파일: 사용한 모델과 최종적인 FID 점수에 대한 설명을 포함하기\n",
        "    2. Colab Notebook 파일: <b>[파일]</b> - <b>[다운로드]</b> - <b>[.ipynb 다운로드]</b>\n",
        "    3. 최종 결과 이미지(마스크 착용 1,000개 및 마스크 미착용 1,000개)가 포함된 압축 파일\n",
        "* 최종 결과 이미지는 다음과 같은 양식으로 압축 파일(.zip) 형태로 제출합니다.\n",
        "    * with_mask와 without_mask 이미지들이 서로 다른 폴더로 확실히 구분되어야 합니다.\n",
        "    * <b>PPT에 기록된 FID 점수와 동일한 점수</b>가 나오는 이미지여야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch1IKehl_NWB"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8-7RwH37MPK"
      },
      "source": [
        "* GAN은 학습이 어려운 네트워크 중 하나입니다.\n",
        "    * 학습 자체가 안 되는 문제가 발생할 수 있습니다. (처음부터 D loss: 0.5, G loss: 1.0 고정되는 문제)\n",
        "    * 같은 레이블에 대하여 거의 똑같은 이미지만 생성될 수 있습니다. (mode collapse)\n",
        "* (Hint) 학습이 잘 안 되는 경우 배치 사이즈, learning rate, 아키텍처를 다시 확인하고 조절합니다.\n",
        "* FID 점수는 이미지 생성을 할 때마다 변경될 수 있습니다.\n",
        "    * 실제로 해당 FID 점수가 나왔는지 확인할 필요가 있으므로, 생성된 이미지 파일(총 2,000장)을 꼭 함께 제출합니다."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
